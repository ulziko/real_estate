# NUM - ML 2025 Spring - Real Estate Assistant
–≠–Ω—ç—Ö“Ø“Ø “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω —Ç—É—Å–ª–∞—Ö –Ω—å –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ —Ü—É–≥–ª—É—É–ª–∂, –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∂, –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π–Ω 
 –ª–∏–Ω–∫ ”©–≥”©—Ö”©–¥ 5 —Ç”©—Ä–ª–∏–π–Ω —Ç–∞–π–ª–∞–Ω –≥–∞—Ä–≥–∞–∂ –º”©–Ω –∞—Å—É—É—Å–∞–Ω –∞—Å—É—É–ª—Ç–∞–¥ —Ö–∞—Ä–∏—É–ª–¥–∞–≥ –±–æ–ª—Å–æ–Ω. 
| –®–∞–∞—Ä–¥–ª–∞–≥–∞ | –•—ç—Ä—ç–≥–∂“Ø“Ø–ª—Å—ç–Ω —Ñ–∞–π–ª | 
|-----------|------------------|
| **Vector Store –∞—à–∏–≥–ª–∞—Ö** (FAISS/Vertex RAG) | `src/.py` |
| **5 —Ç”©—Ä–ª–∏–π–Ω —Ç–∞–π–ª–∞–Ω –≥–∞—Ä–≥–∞—Ö** | `src/.py` | 
| **“Æ–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω —Å–∞–π—Ç scraping** (1212.mn/unegui.mn) | `src/.py`, `src/.py` | 
| **–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç –Ω—ç–≥—Ç–≥—ç—Ö** (Tavily/Bing) | `src/.py` | 
| **PDF —Ç–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö** | `src/.py` | 
| **Chain-of-Thought –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç** | `src/.py` |

## 5 —Ç”©—Ä–ª–∏–π–Ω —Ç–∞–π–ª–∞–Ω–≥–∏–π–Ω –∞–Ω–≥–∏–ª–∞–ª (25 –æ–Ω–æ–æ)

### 1. –û—Ä–æ–Ω —Å—É—É—Ü–Ω—ã “Ø–Ω–∏–π–Ω –¥—É–Ω–¥–∞–∂ (–±–∞–π—Ä—à–ª–∞–∞—Ä)
- File: `multi_agents/agents/research/district_analysis.py`
- –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä—ã–Ω –¥“Ø“Ø—Ä—ç–≥ –±“Ø—Ä—ç—ç—Ä –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –¥—É–Ω–¥–∞–∂ “Ø–Ω—ç, –º¬≤ “Ø–Ω—ç —Ç–æ–æ—Ü–æ–æ–ª–æ—Ö
- Chain-of-Thought: –•–∞–º–≥–∏–π–Ω —Ö—è–º–¥ –¥“Ø“Ø—Ä–≥–∏–π–≥ –∑”©–≤–ª”©—Ö 
  
### 2. –¢“Ø—Ä—ç—ç—Å–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç
- File: `multi_agents/agents/research/rental_analysis.py`
- “Æ–Ω–¥—Å—ç–Ω “Ø“Ø—Ä—ç–≥: –¢“Ø—Ä—ç—ç—Å–∏–π–Ω “Ø–Ω—ç, —Ö—É–≥–∞—Ü–∞–∞, –±–∞–π—Ä—à–ª—ã–Ω —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç
- ”®–≥”©–≥–¥–ª–∏–π–Ω —ç—Ö “Ø“Ø—Å–≤—ç—Ä: unegui.mn –≤–µ–± scraping

### 3. –•—É–≤–∏–π–Ω –æ—Ä–æ–Ω —Å—É—É—Ü/–±–∞–π—à–∏–Ω–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª
- File: `src/.py`
- “Æ–Ω–¥—Å—ç–Ω “Ø“Ø—Ä—ç–≥: –•–æ—Ç—ã–Ω —Ç”©–≤ –±–æ–ª–æ–Ω –∑–∞—Ö—ã–Ω –±“Ø—Å–∏–π–Ω —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç, —ç—Ä—ç–ª—Ç—Ç—ç–π –±“Ø—Å–∏–π–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç
- –•–∞–π–ª—Ç—ã–Ω –Ω—ç–≥—Ç–≥—ç–ª: Bing/Tavily API –∞—à–∏–≥–ª–∞–ª—Ç

### 4. –û—Ñ—Ñ–∏—Å –±–æ–ª–æ–Ω –∞—Ä–∏–ª–∂–∞–∞–Ω—ã —Ç–∞–ª–±–∞–π–Ω –º—ç–¥—ç—ç–ª—ç–ª
- File: `src/.py`
- “Æ–Ω–¥—Å—ç–Ω “Ø“Ø—Ä—ç–≥: –ê—Ä–∏–ª–∂–∞–∞–Ω—ã –∑–æ—Ä–∏—É–ª–∞–ª—Ç—Ç–∞–π “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω “Ø–Ω—ç, —Ö—ç–º–∂—ç—ç–Ω–∏–π –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç

### 5. –ù–∏–π–≥–º–∏–π–Ω –∞—é—É–ª–≥“Ø–π –±–∞–π–¥–∞–ª (–≥—ç–º—Ç —Ö—ç—Ä–≥–∏–π–Ω —Ç“Ø–≤—à–∏–Ω)
- File: `multi_agents/agents/research/safety_agent.py`
- ”®–≥”©–≥–¥–ª–∏–π–Ω —ç—Ö “Ø“Ø—Å–≤—ç—Ä: 1212.mn scraping
- “Æ–∑“Ø“Ø–ª—ç–ª—Ç“Ø“Ø–¥: –•—É–ª–≥–∞–π, –¥—ç—ç—Ä—ç–º, —Ö“Ø—á–∏—Ä—Ö–∏–π–ª–ª–∏–π–Ω –≥—ç–º—Ç —Ö—ç—Ä–≥–∏–π–Ω —Ç“Ø–≤—à–∏–Ω

## –•—ç—Ä—ç–≥–∂“Ø“Ø–ª—ç–ª—Ç–∏–π–Ω –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π –º—ç–¥—ç—ç–ª—ç–ª

### 1. Vector Store 
```python
# faiss_manager.py
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

class FAISSVectorStore:
    def __init__(self):
        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.index = None
        self.documents = []
    
    def create_index(self, documents):
        embeddings = self.model.encode(documents)
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings.astype('float32'))
        self.documents = documents
    
    def search(self, query, k=5):
        query_embedding = self.model.encode([query])
        distances, indices = self.index.search(query_embedding.astype('float32'), k)
        return [(self.documents[i], distances[0][j]) for j, i in enumerate(indices[0])]
```

### 2. Web scrap
```python
# unegui_scraper.py
import requests
from bs4 import BeautifulSoup
import pandas as pd

class UneGuiScraper:
    def __init__(self):
        self.base_url = "https://unegui.mn"
    
    def scrape_rental_data(self):
        """unegui.mnÏóêÏÑú ÏûÑÎåÄ Ï†ïÎ≥¥ ÌÅ¨Î°§ÎßÅ"""
        # Íµ¨ÌòÑ ÏΩîÎìú
        pass
    
    def save_to_csv(self, data, filename):
       
        df = pd.DataFrame(data)
        df.to_csv(f"data/scraped_data/{filename}", index=False)

# safety_scraper.py
class SafetyScraper:
    def scrape_crime_data(self):
        pass
```

### 3. Web search
```python


```

### 4. Chain-of-Thought 
```python
   
```

### 5. PDF —Ç–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö 
```python
# pdf_generator.py
from reportlab.lib.pagesizes import letter, A4
from reportlab.pdfgen import canvas
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
import matplotlib.pyplot as plt

class PDFReportGenerator:
    def __init__(self):
        self.doc = None
        
    def generate_report(self, data):
        """–ë“Ø—Ä—ç–Ω —Ç–∞–π–ª–∞–Ω–≥ PDF —Ñ–æ—Ä–º–∞—Ç–∞–∞—Ä “Ø“Ø—Å–≥—ç—Ö"""
        filename = f"reports/real_estate_report_{datetime.now().strftime('%Y%m%d')}.pdf"
        self.doc = SimpleDocTemplate(filename, pagesize=A4)
        
        # –ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π font –¥—ç–º–∂–ª—ç–≥
        story = []
        styles = getSampleStyleSheet()
        
        # –ì–∞—Ä—á–∏–≥ –Ω—ç–º—ç—Ö
        title = Paragraph("“Æ–õ –•”®–î–õ”®–• –•”®–†”®–ù–ì–ò–ô–ù –¢–ê–ô–õ–ê–ù", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 20))
        
        # 5 –±“Ø–ª–≥–∏–π–Ω —Ç–∞–π–ª–∞–Ω–≥ –Ω—ç–º—ç—Ö
        for section in data:
            story.append(self._create_section(section))
            
        self.doc.build(story)
        return filename
```

##  –§–∞–π–ª—ã–Ω –±“Ø—Ç—ç—Ü –±–æ–ª–æ–Ω —Ç–∞–π–ª–±–∞—Ä

```
real_estate/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ vectorstore/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ faiss_manager.py      # FAISS vector store —É–¥–∏—Ä–¥–ª–∞–≥–∞ (15 –æ–Ω–æ–æ)
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unegui_scraper.py     # unegui.mn-—Å –º—ç–¥—ç—ç–ª—ç–ª —Ç–∞—Ç–∞—Ö (15 –æ–Ω–æ–æ)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ safety_scraper.py     # 1212.mn-—Å –∞—é—É–ª–≥“Ø–π –±–∞–π–¥–ª—ã–Ω –º—ç–¥—ç—ç–ª—ç–ª
‚îÇ   ‚îú‚îÄ‚îÄ search/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_search.py         # Tavily/Bing —Ö–∞–π–ª—Ç (15 –æ–Ω–æ–æ)
‚îÇ   ‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cot_analyzer.py       # Chain-of-Thought –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç (15 –æ–Ω–æ–æ)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ housing_price_analyzer.py   # –û—Ä–æ–Ω —Å—É—É—Ü–Ω—ã “Ø–Ω–∏–π–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rental_analyzer.py          # –¢“Ø—Ä—ç—ç—Å–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ housing_market_analyzer.py  # –•—É–≤–∏–π–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commercial_analyzer.py      # –ê—Ä–∏–ª–∂–∞–∞–Ω—ã —Ç–∞–ª–±–∞–π–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ safety_analyzer.py          # –ê—é—É–ª–≥“Ø–π –±–∞–π–¥–ª—ã–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îÇ       ‚îú‚îÄ‚îÄ report_generator.py   # 5 —Ç”©—Ä–ª–∏–π–Ω —Ç–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö (25 –æ–Ω–æ–æ)
‚îÇ       ‚îî‚îÄ‚îÄ pdf_generator.py      # PDF —Ç–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö (15 –æ–Ω–æ–æ)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ scraped_data/            # –¶—É–≥–ª—É—É–ª—Å–∞–Ω ”©–≥”©–≥–¥”©–ª
‚îÇ   ‚îú‚îÄ‚îÄ processed_data/          # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª—Å–∞–Ω ”©–≥”©–≥–¥”©–ª
‚îÇ   ‚îî‚îÄ‚îÄ vector_stores/           # FAISS –∏–Ω–¥–µ–∫—Å —Ñ–∞–π–ª—É—É–¥
‚îú‚îÄ‚îÄ reports/                     # “Æ“Ø—Å–≥—ç—Å—ç–Ω PDF —Ç–∞–π–ª–∞–Ω–≥—É—É–¥
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py             # API —Ç“Ø–ª—Ö“Ø“Ø—Ä –±–æ–ª–æ–Ω —Ç–æ—Ö–∏—Ä–≥–æ–æ–Ω—É—É–¥
‚îú‚îÄ‚îÄ requirements.txt            # –®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π library-—É—É–¥
‚îî‚îÄ‚îÄ main.py                     # –ì–æ–ª –ø—Ä–æ–≥—Ä–∞–º–º
```















## üíª –ú–æ–¥—É–ª—å —Ç—É—Å –±“Ø—Ä–∏–π–Ω –∞—à–∏–≥–ª–∞–ª—Ç

### Vector Store –∞—à–∏–≥–ª–∞—Ö (15 –æ–Ω–æ–æ)
```python
from src.vectorstore.faiss_manager import FAISSVectorStore

# –ú—ç–¥—ç—ç–ª–ª–∏–π–Ω —Å–∞–Ω–≥–∞–∞—Å —Ö–∞–π–ª—Ç —Ö–∏–π—Ö
vector_store = FAISSVectorStore()
vector_store.load_index("data/vector_stores/property_index.faiss")

# –ò–∂–∏–ª —Ç”©—Å—Ç—ç–π –º—ç–¥—ç—ç–ª—ç–ª —Ö–∞–π—Ö
results = vector_store.search("–°“Ø—Ö–±–∞–∞—Ç–∞—Ä –¥“Ø“Ø—Ä–≥–∏–π–Ω –æ—Ä–æ–Ω —Å—É—É—Ü", k=5)
```

### Web Scraping –∞–∂–∏–ª–ª—É—É–ª–∞—Ö (15 –æ–Ω–æ–æ)
```python
from src.scrapers.unegui_scraper import UneGuiScraper
from src.scrapers.safety_scraper import SafetyScraper

# unegui.mn-—Å –º—ç–¥—ç—ç–ª—ç–ª —Ü—É–≥–ª—É—É–ª–∞—Ö
scraper = UneGuiScraper()
rental_data = scraper.scrape_rental_data()

# 1212.mn-—Å –∞—é—É–ª–≥“Ø–π –±–∞–π–¥–ª—ã–Ω –º—ç–¥—ç—ç–ª—ç–ª
safety_scraper = SafetyScraper()
crime_data = safety_scraper.scrape_crime_data()
```

### –ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç (15 –æ–Ω–æ–æ)
```python
from src.search.web_search import WebSearchManager

search_manager = WebSearchManager()

# Tavily-–∞–∞—Ä —Ö–∞–π—Ö
tavily_results = search_manager.search_tavily("–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥”©")

# Bing-—ç—ç—Ä —Ö–∞–π—Ö
bing_results = search_manager.search_bing("–ú–æ–Ω–≥–æ–ª –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª")
```

### Chain-of-Thought –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç (15 –æ–Ω–æ–æ)
```python
from src.analysis.cot_analyzer import ChainOfThoughtAnalyzer

analyzer = ChainOfThoughtAnalyzer()
recommendation = analyzer.analyze_best_district(price_data)

print("–®–∏–π–¥–≤—ç—Ä–∏–π–Ω –∞–ª—Ö–º—É—É–¥:")
for step in recommendation['reasoning_steps']:
    print(f"  {step}")
```

### PDF —Ç–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö (15 –æ–Ω–æ–æ)
```python
from src.reports.pdf_generator import PDFReportGenerator

pdf_gen = PDFReportGenerator()
report_file = pdf_gen.generate_report(all_analysis_data)
print(f"–¢–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞: {report_file}")
```

## 5 —Ç”©—Ä–ª–∏–π–Ω —Ç–∞–π–ª–∞–Ω–≥–∏–π–Ω –∂–∏—à—ç—ç (25 –æ–Ω–æ–æ)

–°–∏—Å—Ç–µ–º –¥–∞—Ä–∞–∞—Ö –±–∞–π–¥–ª–∞–∞—Ä —Ç–∞–π–ª–∞–Ω –≥–∞—Ä–≥–∞–Ω–∞:

```
=== “Æ–õ –•”®–î–õ”®–• –•”®–†”®–ù–ì–ò–ô–ù –¢–ê–ô–õ–ê–ù ===
–û–≥–Ω–æ–æ: 2025-06-01

1. –û–†–û–ù –°–£–£–¶–ù–´ “Æ–ù–ò–ô–ù –î–£–ù–î–ê–ñ
   Chain-of-Thought –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç:
   - 1-—Ä –∞–ª—Ö–∞–º: ”®–≥”©–≥–¥”©–ª —Ü—É–≥–ª—É—É–ª–∞–ª—Ç
   - 2-—Ä –∞–ª—Ö–∞–º: –î“Ø“Ø—Ä—ç–≥ –±“Ø—Ä—ç—ç—Ä –∞–Ω–≥–∏–ª–∞–ª—Ç
   - 3-—Ä –∞–ª—Ö–∞–º: –î—É–Ω–¥–∞–∂ “Ø–Ω—ç —Ç–æ–æ—Ü–æ–æ–ª–æ–ª
   - 4-—Ä –∞–ª—Ö–∞–º: –•–∞–º–≥–∏–π–Ω —Ö—è–º–¥ –±“Ø—Å –æ–ª–æ—Ö
   
   “Æ—Ä –¥“Ø–Ω: –ë–∞—è–Ω–∑“Ø—Ä—Ö –¥“Ø“Ø—Ä—ç–≥ —Ö–∞–º–≥–∏–π–Ω —Ö—è–º–¥ (2,100,000‚ÇÆ/–º¬≤)

2. –¢“Æ–†–≠–≠–°–ò–ô–ù –ó–ê–• –ó–≠–≠–õ (unegui.mn-—Å —Ü—É–≥–ª—É—É–ª—Å–∞–Ω)
   –¢–∞—Ç—Å–∞–Ω –º—ç–¥—ç—ç–ª—ç–ª: 1,247 –∑–∞—Ä
   –î—É–Ω–¥–∞–∂ —Ç“Ø—Ä—ç—ç—Å: 850,000‚ÇÆ/—Å–∞—Ä
   
3. –•–£–í–ò–ô–ù –°–£–£–¶–ù–´ –ó–ê–• –ó–≠–≠–õ (Tavily/Bing —Ö–∞–π–ª—Ç–∞–∞—Ä)
   –í–µ–± —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω: 15 —ç—Ö —Å—É—Ä–≤–∞–ª–∂
   –ß–∏–≥ —Ö–∞–Ω–¥–ª–∞–≥–∞: “Æ–Ω—ç 5% ”©—Å”©—Ö —Ç”©–ª”©–≤
   
4. –ê–†–ò–õ–ñ–ê–ê–ù–´ –¢–ê–õ–ë–ê–ô
   –û—Ñ—Ñ–∏—Å—ã–Ω –¥—É–Ω–¥–∞–∂ —Ç“Ø—Ä—ç—ç—Å: 45,000‚ÇÆ/–º¬≤/—Å–∞—Ä
   
5. –ê–Æ–£–õ–ì“Æ–ô –ë–ê–ô–î–ê–õ (1212.mn-—Å —Ü—É–≥–ª—É—É–ª—Å–∞–Ω)
   –•–∞–º–≥–∏–π–Ω –∞—é—É–ª–≥“Ø–π: –•–∞–Ω-–£—É–ª –¥“Ø“Ø—Ä—ç–≥
   –ê–Ω—Ö–∞–∞—Ä–∞–ª —Ö–∞–Ω–¥—É—É–ª–∞—Ö: –ë–∞—è–Ω–≥–æ–ª –¥“Ø“Ø—Ä—ç–≥
```
